# Linear-Regression-predict-Gold-Future-Price
利用线性回归思路和深度学习思路对黄金期货价格进行预测，对比一下线性回归LR和最简单的深度学习网络MLP在预测黄金价格上的准确率。
最后得到的结果是，MLP网络预测黄金价格的准确率能达到80%。

## 目的：利用线性回归思路，对来自于Tushare的黄金期货价格数据进行预测
## 说明
多元线性回归（MLR），也称为多元回归，是一种使用多个解释变量来预测响应变量结果的统计技术。

多元线性回归（MLR）的目标是建立线性关系 解释变量（自变量）和反应变量（因变量）之间。 从本质上讲，多元回归是普通最小二乘法（OLS）的推广回归 因为它涉及到不止一个解释变量。

简单线性回归是一个函数，它允许分析员或统计学家根据已知的另一个变量的信息对一个变量进行预测。

只有当一个变量有两个连续变量，一个自变量和一个因变量时，才可以使用线性回归。自变量是用来计算因变量或结果的参数。多元回归模型扩展到几个解释变量。

量化交易模拟流程为：选定交易品种，分析交易品种影响因素，选定交易策略，量化回测，数据回测。
## 选定交易品种
在市场上流通的金融产品主要为三类：期货，现货，股票。

期货，与现货完全不同，现货是实实在在可以交易的货（商品），期货主要不是货，而是以某种大众产品如棉花、大豆、石油等及金融资产如股票、债券等为标的标准化可交易合约。因此，这个标的物可以是某种商品（例如黄金、原油、农产品），也可以是金融工具。

交收期货的日子可以是一星期之后，一个月之后，三个月之后，甚至一年之后。

买卖期货的合同或协议叫做期货合约。买卖期货的场所叫做期货市场。投资者可以对期货进行投资或投机。

股票是股份证书的简称，是股份公司为筹集资金而发行给股东作为持股凭证并借以取得股息和红利的一种有价证券。每股股票都代表股东对企业拥有一个基本单位的所有权。这种所有权是一种综合权利，如参加股东大会、投票表决、参与公司的重大决策、收取股息或分享红利等。同一类别的每一份股票所代表的公司所有权是相等的。每个股东所拥有的公司所有权份额的大小，取决于其持有的股票数量占公司总股本的比重。股票是股份公司资本的构成部分，可以转让、买卖或作价抵押，是资本市场的主要长期信用工具，但不能要求公司返还其出资。股东与公司之间的关系不是债权债务关系。股东是公司的所有者，以其出资份额为限对公司负有限责任，承担风险，分享收益。

相对于繁杂的金融市场来说，期货是一种相对较简单，影响因素较容易分析的种类。而黄金期货是历史研究比较透彻的传统金融期货产品之一。

本文选定研究对象为中国黄金期货。

下表列出与黄金价格变动相关的11个因素。
![image](https://github.com/SHUAIBAO-AI/Linear-Regression-predict-Gold-Future-Price/blob/main/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%9B%BE%E5%86%8C/%E9%BB%84%E9%87%91%E6%9C%9F%E8%B4%A7%E4%BB%B7%E6%A0%BC%E5%BD%B1%E5%93%8D%E5%9B%A0%E5%AD%90.png)

根据一般商品定价理论，传统的供需关系理论对黄金定价机制进行研究时候会提出供给分析与需求分析。

黄金的供给主要来源于金矿开采，再生黄金，央行抛售黄金等三部分。黄金的需求主要来源于制造业工业生成与金融业投资两大类。

对黄金价格时间序列进行平稳性检验：

	将黄金价格时间序列视为离散随机时间序列，根据随机序列平稳过程性质证明，对于任意一个平稳随机序列，任意时刻该序列的状态都在一个常数左右波动，也就是说该平稳序列的均值为一个常数。并且该序列的自相关函数的值只与时间差有关，意味着该平稳序列的自相关函数是时间差的函数。对于黄金价格时间序列来说，黄金价格时间序列在长期时间间隔上，其均值并不会稳定在某常数值附近，意味着黄金价格时间序列在长时间范围内属于不稳定序列。
	
	因为黄金价格时间序列属于非平稳序列，所以通过一阶差分处理获取平稳序列之后，我们建立的协整回归方程通过了平稳性检验。
	
	在黄金价格时间序列分析中，我们最常用的是应用线性回归分析理论对黄金价格时间序列的影响因素进行数学证明。
	
	在具体的模型特征变量筛选过程中，我们主要参考的是以下两个标准：
	
1.	直观图形：观察两种标准的价格曲线走势的相似性或者相反性。
2.	格兰杰因果检验：P统计量值。
在单位根检验证明序列平稳后，对变量进行格兰杰因果检验。原假设为：变量B不能对变量A的变化进行解释，如果检验得到的F统计量大于临界值，或者P统计量很小，则拒绝原假设，认定变量B和A直接存在因果关系。
3.	相关系数（Correlation coefficient，COR）
相关系数是展现变量之间相关关系的统计指标，一般按照积差方法计算。绝对值越接近1，相关性越强。

黄金期货价格在黄金价格回归模型中标准化系数高达0.998，t值为249.06，在1%的水平下表现异常显著，这说明黄金期货价格与黄金价格之间存在高度的协同性。

基于以上分析，我们选取美元指数，美国失业率，VIX恐慌指数，美国新增非农人数，美国CPI等方面的时间序列数据与黄金时间序列数据进行回归分析与相关性分析，证实以上这些数据都与黄金数据有强相关。

### 美元指数 ( US Dollar Index ) 

是加权综合计算美元对英镑、欧元等六种货币汇率情况，从而反映美元在国际外汇市场价值的指标。美元作为世界货币，对黄金价格会产生较大的影响。通常来说，若美元走势强劲，则市场资金倾向于持有美元，黄金价格就会相应走弱。相反，当美元在市场上表现疲软时，黄金就会相应走强。为使得两个数据都在同一区间内表现趋势，我们将数据进行归一化处理。

![image](https://github.com/SHUAIBAO-AI/Linear-Regression-predict-Gold-Future-Price/blob/main/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%9B%BE%E5%86%8C/%E5%9B%BE%E7%89%871.png)

从上面图表中我们可以看出，二者在直观上有相反的特征，在我们取得的时间范畴内，两个变量的相关系数COR为-0.885，有很明显的负相关关系，格兰杰因果检验得到P统计量为0.0399，在5%显著水平下，可以认为美元指数是解释黄金价格变化的1阶格兰杰原因。

### 国债利率
投资黄金最大的缺点是没有利息，投资收益完全依赖于持有期内黄金价格本身的上涨。因此，市场利率高低，将显著影响黄金在投资者心中的吸引力。具体来说，市场利率偏低时，黄金相对而言有优势；但如果市场利率升高，特别是美国利息升高时，持有黄金的机会成本升高，那么无法支付利息的黄金投资价值就会大大下降。
国债利率是对市场利率水平的一个较好的度量指标。目前国际市场上主要的国债利率包括美国十年期国债利率和中国、日本等国的十年期国债利率。考虑到本文实验所用黄金数据为美国纽约交易所 Comex 黄金期货数据，因此我们主要选择美国国债利率：

![image](https://github.com/SHUAIBAO-AI/Linear-Regression-predict-Gold-Future-Price/blob/main/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%9B%BE%E5%86%8C/%E5%9B%BE%E7%89%872.png)

如图所示，我们看到，在本文实验数据时间范围内，二者走势具有一定的相反特征。两个变量的相关系数为-0.538，相关关系比较低；格兰杰因果检验得到 P 统计量值为 0.02067，在5%的显著性水平下可以认为美国十年期国债名义利率也是解释黄金价格变化的 1 阶格兰杰原因。但总体来看，美国国债利率指标与黄金价格间的联系不如美元指数那么强。

### VIX恐慌指数
VIX指数是芝加哥期权交易所市场波动率指数的交易代码，常见于衡量标准普尔500指数期权的隐含波动性。通常被称为“恐慌指数”或“恐慌指标”，它是了解市场对未来30天市场波动性预期的一种衡量方法。
![image](https://github.com/SHUAIBAO-AI/Linear-Regression-predict-Gold-Future-Price/blob/main/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%9B%BE%E5%86%8C/%E5%9B%BE%E7%89%873.png)

如图所示，我们看到，在本文实验数据范围内，二者走势在大多数时间呈现出明显相反的特征，但最近 150 个交易日（即 2016 年以来），也出现了同步上升的局面，笔者认为这可能和 2016 年英国脱欧造成欧洲局势动荡，避险情绪升温有关。两个变量的相关系数为0.627，正相关关系较强；格兰杰因果检验得到 P 统计量值为 0.01632，在5%的显著性水平下认为VIX恐慌指数是黄金价格变化的格兰杰原因。

### 交易回测
	策略回测实际是一种假设和验算，用历史数据套用模型来看盈利怎么样。回测的目既不是为了证伪，也不是为了证实。而是为了计算概率、期望收益率和风险，为投资提供数据决策依据。交易本身就不存在100%的肯定，也不存在100%的否定，我们只能说某条策略，在某个条件的盈利的概率是多少，这属于统计学范畴，所以无论说证伪，还是证实都是不严谨的。
	
既然交易本身就是不确定性的，那么投资的本质就是要做大概率决策。

回测的优势有三：降低试错成本，计算盈利的概率和期望收益，计算风险。

回测可以避免我们在验证策略时候投入资金，避免因策略导致的资金损失，同时与虚拟盘交易不同的是，回测也能帮助我们减少时间成本的损失。因为虚拟盘交易验证后需要改变参数并且等待一段时间之后才能看出结果。

除去减少资金与时间损失之外，一条策略，经过多个样本的数据回测之后就可以计算出这条策略的盈利概率和平均收益率。比如：回测100个样本，盈利60次，平均收益30%，那么这个策略的期望收益率=60%x30%=18%。

计算风险。假设我们已经计算出了期望收益是18%，看上去好像还不错哦，那到底能不能投呢。别急，我们还得计算出一个数字指标叫最大回撤率。比如：还是这条策略，期望收益18%，但是最大回撤20%，如果我点背，可能收益刚到18%，结果来了一个回撤，还亏了2%。于是又多了一个指标，叫夏普率，即每承担一单位的风险所能获得期望回报率。通过对不不同投资策略的夏普率，我们就能做出最佳选择。

### 机器学习
概率与统计学中，贝叶斯学派认为世界是不确定的，因获取的信息不同而异。贝叶斯学派假设对世界先有一个预先的估计，然后通过获取的信息来不断调整之前的预估计。他们不试图对事件本身进行建模，而是从旁观者的角度来说。因此对于同一个事件，不同的人掌握的先验不同的话，那么他们所认为的事件状态也不同。

贝叶斯学派认为模型参数源自某种潜在分布，希望从数据中推知该分布。对于数据的观测方式不同或者假设不同，那么推知的该参数也会存在差异。这就是贝叶斯视角下用估计参数常用方法-MAP，这种方法在先验假设比较靠谱的情况下效果显著，随着数据量的增加，先验假设对于模型参数的主导作用会逐渐削弱，相反真实的数据样例会大大占据有利地位。极端情况下，比如把先验假设去掉，或者假设先验满足均匀分布的话，那她和极大似然估计就如出一辙了。

总之，MLF和MAP都是在解决这样的问题：根据已知的一堆数据样本，来推测产生数据的模型参数，既已知数据，推模型和参数。这也正是我们要用到的机器学习的核心思想之一。

我们在处理weight部分时候要尽量取小weight，因为小weight对数据的波动性抵抗性更好。

### 数据来源
直接与每一个交易所都建立联系，自己实时进行搜集与清洗。但这样的后果就是，我们需要在多个市场与多个交易所内的多个金融产品都建立直接联系，这样的数据源数量会非常庞大，针对于特定的数据源我们都要有特定的软件与处理规则进行搜集与清洗。

其中，主要的数据源及数据种类：

交易所提供：股票数据与期货数据的价格，交易量，时间戳，持仓量，持仓量，订单薄数据等等。其中期货数据源包括：股指期货，商品期货，国债期货。

政府数据源提供：宏观经济数据，如失业率、通货膨胀以及GDP数据等等。

宏观数据体现了一个国家经济发展的现状。任何策略只要资产存在风险暴露，则必然要考虑金融市场行情和宏观因素的影响，包括：经济指标环比；国内生产总值；工业增加值；行业增加值；商品房销售；消费品零售；电力工业数据；就业基本情况；固定资产投资；居民消费水平；物价指数；景气指数等。

在确定了具体的数据源方面后，我们需要确定自己是按什么频率获取数据。

按不同的频率获取数据，我们可以分为历史高频数据源和实时数据源。

历史高频数据即指日内的数据，主要针对以小时、分钟或秒为采集频率的数据，常见历史高频数据字段有：分笔高频数据，分时高频数据。

实时数据源：包含Level1数据和Level2数据。Level1行情属于传统行情。Level-2行情是在Level-1行情基础上设计的具有增值内容的新行情，包括十档买卖行情、总买总卖、逐笔成交明细、买卖队列。

数据提取方法分为终端提取方法和API提取方法两种。

终端提取方法：终端包括有网页终端和软件终端，其提取方法是利用终端界面上的行业分类和字段筛选等提取相关数据，并最终导出 Excel、DBF或TXT等格式文件。

中国提供终端的主流金融数据库主要有：CSMAR数据库、Wind数据库、恒生聚源数据库、锐思数据库、中国统计局数据库、巨潮数据库和巨灵。

API提取方法：API提取方法主要是利用MATLAB、C++、.NET、COM和Excel等软件连接数据库服务器，并通过相关函数字段提取数据库数据。

数据可以分为两大类，价格数据（price data）与基本面数据（fundamental data）。

价格数据不仅仅是金融价格相关的数据，也包括从交易行为中得到或提取的其他相关的数据信息，例如交易量，每笔交易的时间，交易的规模等等。实际上，整个指令簿都能被认为是价格数据，同样的，各类指标数据（例如标准普尔500数据）也被归类为价格数据。

基本面数据的定义实际非常宽泛，因而很难进行有效分类。但从金融意义上讲，基本面数据是除了价格数据之外的所有数据。这些数据的共同特征是：这些数据有助于决定金融产品未来的价格或者描述金融产品目前的状况。

最常见的基本面数据种类是：财务健康状况（financial health），财务表现（financial performance），财物价值（financial worth）和情绪（sentiment）等。例如，公司的资产负债表常用于表现公司的财务健康情况，利润表和现金流量表的指标（总净利润，自由现金流）可以用来考察公司的财务表现。经济学家对下一季度GDP增长情况的预测属于宏观经济的情绪类数据。

数据按照形式可分为数字形式和文本形式。

大部分价格数据倾向于关注短期效应，讨论的对象都是每日甚至是日间连续数据。但在基本面数据中，我们看到的是数据常常是以周、月度甚至是季度为单位的数据。因而，一般使用价格数据的交易策略都是短期策略，一般使用基本面数据的交易策略都是长期策略。

通常来说，模型的细节就是由所用的输入变量的特征决定的。例如，如果我们得到的都是缓慢变化的宏观经济数据，例如美国每个季度的GDP数据等，并且在这些数据公开后我再过一个周才能得到它们，在这样的情况下，我是不可能得到一个可以指导我按天甚至按分钟进行快速交易的模型的。同样的，提供有效的数据建立有效的模型也非常重要。例如，美国的失业率数据变化不可能影响乌拉圭证券市场。

量化交易有一句名言是：“Rubbish In，Rubbish Out“，如果数据的搜集与预处理没有做好，那我们就很难期望模型产生准确甚至是仅仅可用的结果。

错误的数据会导致浪费大量的计算资源与时间，在极端情况下甚至只能得到毫无意义的结论。因而大部分量化交易公司都是自己从源头直接搜集数据，但是对于没有能力搜集数据的个人来说，数据供应商成了最佳选择。因为这些数据供应商在快速得到数据，清洗数据，储存数据等方面有大量的经验。

本文使用的数据来源于tushare和yahoo finance，时间间隔为2012年到2020年，类型包括黄金价格数据，VIX恐慌数据，美元指数，美国国债数据，时间频率为日内数据，每一个方面都包含每日开盘数据，收盘数据，最高数据，最低数据等。其中，黄金价格数据包含6个衡量维度，VIX恐慌数据包含6个衡量维度，美元指数数据包含13周、5年、10年、30年数据，平均每个时间段数据包含6个衡量维度，美国国债收益率曲线数据包含1月期、1年期、短期国债利率、长期国债利率、长期实际国债利率等6个方面数据。


### 数据集预处理与划分
尽管我们在获取数据过程中通过原始数据或者第三方数据供应商能获得标准化的数据，但仍然会遇到数据缺失或错误的情况。因此，在不同的情况下我们有不同的处理方法。

第一类常见的数据问题是缺失值。这类情况是数据确实存在，但是由于客观原因，我们无法获得此类数据，这被称为数据缺失。而如果我们只用整体数据的部分数据来运行模型的话，模型可能就会得出一个错误的结果。解决数据缺失的方法有很多，其中两种常见的方法：一是建立允许数据出现缺失的系统，这样的系统在某时间段内如果没有数据，它就不会运行。例如我们预处理数据中将缺失的数据赋值为0，因为0和缺失在很多场景下的性质是一样的。另外一种处理缺失值的方法是插值，在前后两个数据之间利用插值理论补上合理的数据。但是插值方法仅仅对历史数据产生作用，对于高频实时数据并没有作用。例如，假设我们知道一个时间段内开头和结尾时间的价格，我们想要知道这个时间段中间时间的价格，我们最常用的插值方法是中间时间段取两个时间点价格的平均值。尽管这样的插值不太精确，但至少它是合理的。

第二类常见的错误值是错误观测值。例如小数点错误。比如在英国股票市场上，有时它的数据会以英镑为单位，有时它的数据会以便士为单位。如果系统默认是以英镑为单位，但接收的数据在没有标注单位的情况下是以便士为单位的话，那么会导致时间序列前后数值相差波动很大，对于部分没有数据审核机制的模型来说，这就是错误的观测值。因而，错误的观测值指的就是根本不会出现的数值或者不会以数据源所预示的方式出现的数据。

为解决错误观测值，当前常用的方法之一是异常值过滤（Spike Filter）。异常值过滤指的是寻找价格数据中波动幅度很大的值，对其进行平滑或者直接删除。但是不可避免的是，我们在处理异常值的过程中，也有可能会过滤掉正常的大幅度波动，例如2020年4月21日的期货原油市场，当地时间20日收盘，即将于21日到期的纽约商品交易所5月交货的轻质原油期货价格大跌305.97%,报收-37.63美元；6月交货的轻质原油期货价格也大幅下跌18.37%，报收每桶20.43美元。同时，6月交货的伦敦布伦特原油期货价格下跌2.51美元，报收每桶25.57美元，跌幅为8.94%。

此类异常点在初始判定中被认为是错误值，但实际上它是真实存在的点。因而解决此类问题的方法之一是：人工判定与多数据源交叉验证。其中人工判定指的是辅助监管人员查证检测此异常数据。但问题在于非专业人士很难判定其是否属于真正的观测错误。而多数据源交叉验证指的是来源于多个数据供应商的数据都不匹配的时候，其中至少有一家的数据是有问题的。常用的数据清洗方法处理与处理缺失数据类似，都是通过观察坏点前后的值进行插值处理。

除去数据缺失与数据丢失的问题之外，在时间序列分析中，我们更为隐蔽的一个问题是前视偏差（Look-ahead bias）。此类情况指的是在某事情真实发生之前我们就错误假设自己已经知道了相关的信息，这是由于数据的不同步性造成的。

前视偏差非常典型的例子就是公司财报对股价的影响。公司每季度上报给监管当局的财务报表文档会在每个季度末的4到8周之后才会公开发布。假设在2010年第一季度结束时候，公司第一季度的利润是每股1美元，但我们在3月31日预计的利润是每股0.5美元。在数据供应商得到公司利润是每股1美元的时候，就会把在5月1号发布的每股1美元利润数据更替掉3月31日的预期数据。而在此之后，当我们提取相关的收益数据进行交易策略验证时，数据中3月31日记录的时2010年第1季度此公司每股收益是1美元，所以交易模型会认为这是真实的数据。但是实际上，在5月1日发布之前，交易模型是不会知道这一数字的。只有在5月1日以后这个数据才会被公布出来。这类问题的核心在于：我们以为自己可以获得修正过的数据吗，但实际上他只能得到不太准确的初始数据。

在这个错误基础上，我们的模型会让我们觉得自己的策略能带来有效的收益。但实际上数据本身就是错误的，因而在实际操作过程中，我们并不能稳定获得收益。

为了解决前视误差，我们可以记录下更新后的数据发布的日期，并且在模型验证时，只在合理时间段内使用这些数据。

同样的，另外一种数据不同步性的来源是世界上不同交易所收盘时间不一样。因时区差距，中国，美国，欧洲等三地的交易所开盘与结束交易时间各不一样。很多情况下，美国的新闻与交易活动的影响对欧洲和亚洲的影响直到第二天才能体现出来。因而应对这样的问题，我们可以采取单一地区数据来源。

在处理完数据清洗与规范化问题后，我们需要对机器学习模型应用数据集划分。

按照规范，我们的数据划分为训练集，验证集和测试集。比例为6：2：2。

为什么我们需要用小数据集进行划分呢？因为我们想要充分利用有限的数据集，找到合适的参数模型，但是又要防止过拟合。这时候，k折交叉验证（k-fold cross validation）与留出法（holdout cross validation）成了最通用的数据集划分方法。

交叉验证用于评估模型的预测性能，尤其是训练好的模型在新数据上的表现性能，也可在一定程度上减小过拟合。也能尽量从有限的数据中获得尽可能多的信息。

交叉验证的目的：在实际训练中，模型通常对训练数据拟合程度好，但是对训练数据之外的数据拟合程度差。交叉验证可以用于评价模型的泛化能力，从而进行模型选择。

交叉验证的基本思想：把在某种意义下将原始数据(dataset)进行分组,一部分做为训练集(train set),另一部分做为验证集(validation set or test set),首先用训练集对模型进行训练,再利用验证集来测试模型的泛化误差。另外，现实中数据总是有限的，为了对数据形成重用，我们就提出了k-折叠交叉验证。

对于分类或回归问题，假设可选的模型为M={M_1,M_2,M_3……M_d}。k-折叠交叉验证就是将训练集的1/k作为测试集，每个模型训练k次，测试k次，错误率为k次的平均，最终选择平均率最小的模型M_i。

1、 将全部训练集S分成k个不相交的子集，假设S中的训练样例个数为m，那么每一个子集有m/k个训练样例，相应的子集称作{}。
2、 每次从模型集合M中拿出来一个，然后在训练子集中选择出k-1个{}（也就是每次只留下一个），使用这k-1个子集训练后，得到假设函数。最后使用剩下的一份作测试，得到经验错误。
3、 由于我们每次留下一个（j从1到k），因此会得到k个经验错误，那么对于一个，它的经验错误是这k个经验错误的平均。
4、 选出平均经验错误率最小的，然后使用全部的S再做一次训练，得到最后的。

在数据处理部分时候，我们不能借鉴原例子（《深度学习入门之PyTorch》第五章RNN的Demo）中的处理方式，即将输入输出错位，构建出很多个时间序列。例如第一行是1~7个月的，第二行是2~8个月的，因为原例子序列数目越多，网络的泛化能力越好。原例子中“将输入输出错位 构建出很多个时间序列”的方法在RNN中是累赘的，这不会给模型带来提升（不会提升预测精度，更不会提升泛化性），只会增加模型运行时间（需要计算的东西变多了）。

因为我们的全部数据只是一条长度为2024的短序列，因此为了尽可能地利用手上的数据，我们需要对序列进行裁剪。（在图像的训练中也有类似的做法：我对图像进行轻微的旋转、裁剪去做数据增广用于增加训练数据）。

在RNN(LSTM)中，对循环网络的训练与对普通深度神经网络的训练是不同的，因此我们不能随意地裁剪序列用于RNN的训练。例如我们随便截取序列编号1949到1950的数据输入RNN用于训练，这相当于让RNN在“以1950为开头的所有序列”上都进行了训练。所以我们要在不同的起始位点进行裁剪来为RNN提供「没有训练过的材料」。

要注意的是，输入多个拥有相同起始剪裁位点的序列给RNN用于训练是完全错误的训练方式。当我们输入一个序列给RNN时，合格的深度学习框架中的RNN已经帮我们训练了拥有相同起始位点的所有序列，这时候还额外输入其余的具有相同起始剪裁位点的序列给RNN会导致RNN更快地过拟合。由于数据量非常少，所以我们只能使用同一个batch进行训练，这个方法非常容易过拟合，但是因为有这样的方法，所以我们不需要训练太久，几秒钟就能训练出来。

我们总的数据维度为（2024，62），即2024天的[黄金价格数据，VIX恐慌数据，美元指数，美国国债数据]这四个方面，共62个维度的数据。在获得数据之后我们对数据进行归一化处理（减去平均值，除以标准差）。其中，进行归一化处理的方式为对训练的前60%的数据进行归一化处理，后面的20%的测试数据与20%的验证数据都不进行归一化处理。

![image](https://github.com/SHUAIBAO-AI/Linear-Regression-predict-Gold-Future-Price/blob/main/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%9B%BE%E5%86%8C/%E5%9B%BE%E7%89%874.png)
上图是Linear Regression方法对价格数据预测与历史价格数据的拟合程度

![image](https://github.com/SHUAIBAO-AI/Linear-Regression-predict-Gold-Future-Price/blob/main/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%9B%BE%E5%86%8C/%E5%9B%BE%E7%89%875.png)

在多元线性回归网络中，我们读取过去10年间每天的黄金价格数据，删除NaN值。解释变量被定义为第二天黄金价格数值的变量，本次实验中自变量定义为时间序列中所有的变量维度，按照我们数据预处理部分的介绍，变量数量为63。因变量被定义为我们试图预测的黄金期货价格。

	与标准的机器学习流程相似，我们把数据切分为训练集与测试集。前75%的数据用于训练模型，后面25%的数据用于测试。设定训练阈值为0.1。
	
正如我们在上图中所看到的，当我们随机取2018年4月到2020年7月之间的日数据进行线性回归拟合的时候，我们可以通过历史数据很好地拟合过去的数据，我们也能做到拟合数据无限逼近于真实数据，但是在预测未来的验证集合上，我们却无法获取如此高的正确率。究其根本，是我们当前拟合过程中并未严格区分信号与噪声。而众所周知的是，在金融市场中，我们的金融时间序列包含了大量的噪声信号，因而单纯的多元线性回归分析并不能有效地预测。

	多元线性回归网络运行10次取平均值为该网络的预测准确度，最后确定在黄金时间序列上的预测准确度为25%。
	
## 多层感知机网络预测结果
相对简单的线性回归分析来说，BP网络能拟合更多的非线性关系，并且由于BP网络天然的优势，BP网络可以设置更加复杂的非线性关系。

![image](https://github.com/SHUAIBAO-AI/Linear-Regression-predict-Gold-Future-Price/blob/main/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%9B%BE%E5%86%8C/%E5%9B%BE%E7%89%876.png)
这个MLP网络，我选择设定两层全连接层，每层隐藏层保持与数据维度相同数量的隐层节点数，输出为二分类。对于此网络来说，最简单的MLP网络结构能够完全拟合黄金价格数据的非线性趋势。


![image](https://github.com/SHUAIBAO-AI/Linear-Regression-predict-Gold-Future-Price/blob/main/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%9B%BE%E5%86%8C/%E5%9B%BE%E7%89%877.png)

MLP的同样的，对于此网络我们每个结果都运行10次取平均值，确定MLP网络在时间序列上的预测精度为80%左右。

所以结论是：
采用简单的MLP网络，可以以高达80%的正确率去预测未来的黄金价格。



